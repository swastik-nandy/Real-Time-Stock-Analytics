{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5CHsFrKPJBL",
        "outputId": "481e874f-1eb3-461d-c0a0-d32d488824c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 135786 entries, 0 to 135785\n",
            "Data columns (total 4 columns):\n",
            " #   Column            Non-Null Count   Dtype  \n",
            "---  ------            --------------   -----  \n",
            " 0   id                135786 non-null  int64  \n",
            " 1   stock_id          135786 non-null  int64  \n",
            " 2   price             135786 non-null  float64\n",
            " 3   trade_time_stamp  135786 non-null  object \n",
            "dtypes: float64(1), int64(2), object(1)\n",
            "memory usage: 4.1+ MB\n",
            "135786\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"stock_price_history.csv\")\n",
        "df.head()\n",
        "df.info()\n",
        "df.head()\n",
        "\n",
        "print (len(df))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sg48qOy-QPDj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Cleanup\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Load CSV\n",
        "df = pd.read_csv(\"stock_price_history.csv\")\n",
        "\n",
        "# Clean & preprocess\n",
        "df['trade_time_stamp'] = pd.to_datetime(df['trade_time_stamp'], errors='coerce')\n",
        "\n",
        "# Drop rows with invalid timestamps or missing prices\n",
        "df.dropna(subset=['trade_time_stamp', 'price'], inplace=True)\n",
        "\n",
        "# Drop duplicates\n",
        "df.drop_duplicates(inplace=True)\n",
        "\n",
        "# Filter out invalid price entries (<= 0)\n",
        "df = df[df['price'] > 0]\n",
        "\n",
        "# Optional: remove rows with absurd jumps (optional for smoothing)\n",
        "df.sort_values(by=['stock_id', 'trade_time_stamp'], inplace=True)\n",
        "df['pct_change'] = df.groupby('stock_id')['price'].pct_change()\n",
        "df = df[df['pct_change'].abs() < 0.5]  # Remove sudden 50%+ spikes\n",
        "df.drop(columns='pct_change', inplace=True)\n",
        "\n",
        "# Final sort & reset index\n",
        "df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Show result\n",
        "df.head()\n",
        "\n",
        "print(f\"✅ Rows remaining after cleanup: {len(df)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0HFzR4hzQ1_9",
        "outputId": "ed2cb9ad-55d1-4700-86ec-8adc055838fe"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Rows remaining after cleanup: 135767\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2422355554.py:24: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.drop(columns='pct_change', inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Parameters\n",
        "WINDOW_SIZE = 60      # last 10 minutes (at 10s interval)\n",
        "LOOKAHEAD = 3         # next 30 seconds\n",
        "THRESHOLD = 0.003     # 0.3% for NEUTRAL zone\n",
        "\n",
        "# Output containers\n",
        "X = []\n",
        "y = []\n",
        "meta = []\n",
        "\n",
        "def get_label(curr_price, future_price, threshold):\n",
        "    change = (future_price - curr_price) / curr_price\n",
        "    if change > threshold:\n",
        "        return 1  # UP\n",
        "    elif change < -threshold:\n",
        "        return 0  # DOWN\n",
        "    else:\n",
        "        return 2  # NEUTRAL\n",
        "\n",
        "# Slide over each stock separately\n",
        "for stock_id, group in df.groupby('stock_id'):\n",
        "    prices = group['price'].values\n",
        "    timestamps = group['trade_time_stamp'].values\n",
        "\n",
        "    for i in range(WINDOW_SIZE, len(prices) - LOOKAHEAD):\n",
        "        window = prices[i - WINDOW_SIZE:i]             # last 60 prices\n",
        "        current_price = prices[i - 1]                  # price at t\n",
        "        future_price = prices[i + LOOKAHEAD - 1]       # price at t+3 (≈30s later)\n",
        "\n",
        "        label = get_label(current_price, future_price, THRESHOLD)\n",
        "\n",
        "        X.append(window)\n",
        "        y.append(label)\n",
        "        meta.append({\n",
        "            'stock_id': stock_id,\n",
        "            'predict_time': timestamps[i + LOOKAHEAD - 1]\n",
        "        })\n",
        "\n",
        "# Convert to arrays\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "meta_df = pd.DataFrame(meta)\n",
        "\n",
        "# Output summary\n",
        "classes, counts = np.unique(y, return_counts=True)\n",
        "class_map = {0: \"DOWN\", 1: \"UP\", 2: \"NEUTRAL\"}\n",
        "print(\"✅ Class distribution:\")\n",
        "for c, cnt in zip(classes, counts):\n",
        "    print(f\"{class_map[c]}: {cnt} samples\")\n",
        "\n",
        "print(f\"✅ Feature shape: X = {X.shape}, y = {y.shape}\")\n"
      ],
      "metadata": {
        "id": "87jsVVCyR2m1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c8bd562-d392-4c8f-83f7-bfe6d967e790"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Class distribution:\n",
            "DOWN: 1020 samples\n",
            "UP: 1105 samples\n",
            "NEUTRAL: 132445 samples\n",
            "✅ Feature shape: X = (134570, 60), y = (134570,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape to (samples, 60, 1) since WINDOW_SIZE is now 60\n",
        "X = X.reshape((X.shape[0], X.shape[1], 1))\n",
        "\n",
        "# Normalize each feature column-wise\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X.reshape(X.shape[0], -1)).reshape(X.shape)\n",
        "\n",
        "# Split\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_scaled, y, test_size=0.2, stratify=y, random_state=42\n",
        ")\n"
      ],
      "metadata": {
        "id": "r7cdGck_SJg4"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PriceDirectionDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = torch.tensor(X, dtype=torch.float32)  # (N, 30, 1)\n",
        "        self.y = torch.tensor(y, dtype=torch.long)     # Labels: 0, 1, 2\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "train_ds = PriceDirectionDataset(X_train, y_train)\n",
        "val_ds = PriceDirectionDataset(X_val, y_val)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=256, shuffle=True)\n",
        "val_loader = DataLoader(val_ds, batch_size=256)\n"
      ],
      "metadata": {
        "id": "Qb6OezYoSSF_"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class CNNPriceClassifier(nn.Module):\n",
        "    def __init__(self, input_length=60):\n",
        "        super().__init__()\n",
        "        self.input_length = input_length\n",
        "\n",
        "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=64, kernel_size=3)\n",
        "        self.bn1 = nn.BatchNorm1d(64)\n",
        "        self.pool1 = nn.MaxPool1d(2)\n",
        "\n",
        "        self.conv2 = nn.Conv1d(64, 128, kernel_size=3)\n",
        "        self.bn2 = nn.BatchNorm1d(128)\n",
        "        self.pool2 = nn.MaxPool1d(2)\n",
        "\n",
        "        # Dynamically compute flattened size\n",
        "        with torch.no_grad():\n",
        "            dummy = torch.zeros(1, 1, input_length) # Batch size 1, 1 channel, input_length\n",
        "            x = self.pool1(F.relu(self.bn1(self.conv1(dummy))))\n",
        "            x = self.pool2(F.relu(self.bn2(self.conv2(x))))\n",
        "            self.flattened_size = x.view(1, -1).shape[1]\n",
        "\n",
        "\n",
        "        self.fc1 = nn.Linear(self.flattened_size, 64)\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.fc2 = nn.Linear(64, 3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.permute(0, 2, 1)  # (B, 1, 60)\n",
        "        x = self.pool1(F.relu(self.bn1(self.conv1(x))))\n",
        "        x = self.pool2(F.relu(self.bn2(self.conv2(x))))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        return self.fc2(x)"
      ],
      "metadata": {
        "id": "5pGY0qYO76kV"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "import torch\n",
        "\n",
        "# Count class frequencies in y_train\n",
        "class_counts = Counter(y_train)\n",
        "total = sum(class_counts.values())\n",
        "\n",
        "# Inverse frequency weights\n",
        "weights = torch.tensor([\n",
        "    total / class_counts[0],  # DOWN\n",
        "    total / class_counts[1],  # UP\n",
        "    total / class_counts[2]   # NEUTRAL\n",
        "], dtype=torch.float32)\n",
        "\n",
        "weights = weights / weights.sum()  # Optional: normalize\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Model, optimizer, criterion\n",
        "model = CNNPriceClassifier(input_length=60)\n",
        "model.to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss(weight=weights.to(device))\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(1, 31):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for X_batch, y_batch in train_loader:\n",
        "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model(X_batch)\n",
        "        loss = criterion(output, y_batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X_batch, y_batch in val_loader:\n",
        "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "            output = model(X_batch)\n",
        "            preds = torch.argmax(output, dim=1)\n",
        "            correct += (preds == y_batch).sum().item()\n",
        "            total += y_batch.size(0)\n",
        "\n",
        "    acc = correct / total\n",
        "    print(f\"Epoch {epoch}: Loss = {total_loss:.4f} | Val Accuracy = {acc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "mTP_bzH08DPA",
        "outputId": "7f495147-3df8-473c-ce42-86cc0c4d699d"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Loss = 466.8561 | Val Accuracy = 0.9842\n",
            "Epoch 2: Loss = 458.6734 | Val Accuracy = 0.9842\n",
            "Epoch 3: Loss = 459.8231 | Val Accuracy = 0.9842\n",
            "Epoch 4: Loss = 458.5150 | Val Accuracy = 0.9842\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2232986024.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    624\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m             )\n\u001b[0;32m--> 626\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    627\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    824\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "joblib.dump(model, \"crypto_xgb_model.pkl\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RApjdeLT-_F7",
        "outputId": "9c878b9f-023d-4c9c-d7e2-89fa5836c39f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['crypto_xgb_model.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    }
  ]
}